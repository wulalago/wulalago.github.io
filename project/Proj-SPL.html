<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Projects</title>
    <link rel="stylesheet" type="text/css" href="../stylesheet.css">
</head>
<body>
<table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research: View Planning in Ultrasound</heading>
            <br>
            <hr>
            <center><h2> Standard Plane </h2></center>
            <p>
                The standard plane is a specific imaging view in an ultrasound video or volumetric scan. It typically
                contains particular anatomical structures or regions of interest to help the sonographer diagnose.
                Generally, during the diagnosis, sonographers first scan pregnant women to obtain ultrasound data, then
                manually localize standard planes (SPs) from them. Next, they measure biometrics on the planes and make
                the diagnosis. Of these, SP acquisition is vital for subsequent biometric measurement and diagnosis.
                However, it is very time-consuming to acquire nearly thirty SPs during the diagnosis, and the process
                often requires extensive experience due to the large difference in fetal posture and the complexity of
                SP definitions.
            </p>
            <p>
            <center><img src=../img/Abc-SPL.png style="width:80%"></center>
            </p>
            <hr>
            <center><h2>Start from industrial</h2></center>
            <div style="text-align: center"><a href="https://arxiv.org/abs/2210.01607">S-Fetus: Automates Obstetric
                Ultrasound Workflow</a></div>
            <p>
                Starting in 2017, we collected over 10k fetal ultrasound videos with 1 million image frames. We built and
                evaluated an AI-driven SP localization model on this collection and successfully deployed it as a plugin
                in the Wis+ ultrasound platform in S60 color doppler diagnostic ultrasound system in SonoScape Co., Ltd..
            </p>
            <p>
            <center><img src=../demo/Demo-S60.gif style="width:80%;"></center>
            </p>
            <hr>
            <center><h2>Towards 3D ultrasound with reinforcement learning</h2></center>
            <div style="text-align: center"><a href="https://link.springer.com/chapter/10.1007/978-3-030-32254-0_33">
                Agent with Warm Start and Active Termination for Plane Localization in 3D Ultrasound</a></div>
            <div style="text-align: center"><a href="https://ieeexplore.ieee.org/abstract/document/9389756">Agent With
                Warm Start and Adaptive Dynamic Termination for Plane Localization in 3D Ultrasound</a></div>
            <p>
                We propose the first reinforcement learning (RL) framework to localize fetal brain SPs in prenatal US
                volumes. First, we equip the RL framework with a landmark-aware alignment module for a warm start to
                ensure its effectiveness. All the volumatric data are aligned to a plane-specific atlas to provide
                strong spatial bounds for RL agent actions. Then, instead of passively and empirically terminating the
                agent inference, we propose a recurrent neural network (RNN) based strategy for active termination of
                the agent’s interaction procedure. The RNN-based strategy can find the optimal termination point
                adaptively, so it improves the accuracy and efficiency of the localization system at the same time.
            </p>
            <p>
            <center><img src=../img/Method-RLSPL.png style="width:80%;"></center>
            </p>
            <p>
                Robotic demo of the reinforcement learning for searching the standard plane:
                <br>
            <center><img src=../demo/Demo-RLSPL.gif style="width:80%;"></center>
            </p>

            <hr>
            <center><h2>Tangent-based formulation</h2></center>
            <div style="text-align: center"><a href="https://link.springer.com/chapter/10.1007/978-3-031-16440-8_29">
                Agent with Tangent-Based Formulation and Anatomical Perception for Standard Plane Localization in 3D
                Ultrasound</a></div>
            <p>
                We define a new tangent-point-based plane formulation in RL to restructure the action space and
                significantly reduce the search space; we design an auxiliary task learning strategy to enhance the
                model’s ability to recognize subtle differences crossing Non-SPs and SPs in plane search; we propose a
                spatial-anatomical reward to effectively guide learning trajectories by exploiting spatial and
                anatomical information simultaneously.
            </p>
            <p>
            <center><img src=../img/Method-TangentRL.png style="width:80%;"></center>
            </p>

            <hr>
            <center><h2>Collaborated Works</h2></center>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='../img/Result-NASSPL-MedIA.png' width=100%>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/pii/S1361841521001651">
                            Searching Collaborative Agents for Multi-plane Localization in 3D Ultrasound
                        </a>
                        <br>
                        Xin Yang, Yuhao Huang, Ruobing Huang, <strong>Haoran Dou</strong>, Rui Li, Jikuan Qian,
                        Xiaoqiong Huang, Wenlong Shi, Chaoyu Chen, Yuanji Zhang, Haixia Wang, Yi Xiong, Dong Ni
                        <br>
                        <em>Medical Image Analysis</em>, 2021
                    </td>
                </tr>
                </tbody>
            </table>

        </td>
    </tr>


    </tbody>
</table>
</body>
</html>