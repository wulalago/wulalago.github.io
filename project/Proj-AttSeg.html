<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Projects</title>
    <link rel="stylesheet" type="text/css" href="../stylesheet.css">
</head>
<body>
<table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research: Attention Mechanism in Segmentation</heading>
            <br>
            <hr>
            <center><h2> Attention Mechanism </h2></center>
            <p>
                The attention mechanism in deep learning lets neural networks focus on specific regions of interest in
                medical data. It works by computing attention scores for each element/pixel in a sequence or image,
                determining their relevance. These scores are used to guide the model to pay more attention to the
                important elements/pixels. Finally, a weighted sum of the input elements produces a context vector,
                capturing the most relevant information for the task at hand. This mechanism enhances the model's
                ability to handle various types of data and has become a crucial component in medical imaging domains.
            </p>
            <p>
            <center><img src=../img/Abc-Att.png style="width:80%"></center>
            </p>
            <hr>
            <center><h2>Attention from multi-scale to single-scale</h2></center>
            <div style="text-align: center"><a href="https://ieeexplore.ieee.org/document/8698868">Deep Attentive
                Features for Prostate Segmentation in 3D Transrectal Ultrasound</a></div>
            <p>
                The schematic illustration of our prostate segmentation network equipped with attention modules. FPN:
                feature pyramid network; SLF: single-layer
                features; MLF: multi-layer features; AM: attention module; ASPP: atrous spatial pyramid pooling. The
                core of our presented framework is to fully exploit the useful complementary information encoded in the
                multi-level features to refine the features at each individual layer. Specifically, we achieve this by
                developing an attention module, which can automatically learn a set of weights to indicate the
                importance of the features in MLF for each individual layer.
            </p>
            <p>
            <center><img src=../img/Method-AttProstateUS.png style="width:80%;"></center>
            </p>
            <hr>
            <h2 style="text-align: center">Mixed kernel attention mechanism</h2>
            <div style="text-align: center"><a href="https://ieeexplore.ieee.org/document/9303459">A Deep Attentive
                Convolutional Neural Network for Automatic Cortical Plate Segmentation in Fetal MRI</a></div>
            <p>
                Schematic illustration of the architecture of our attention module, which takes an input feature map and
                generates a refined attentive feature map of the same size. The module includes two layers of group
                convolutional blocks followed by feature concatenation and 1 × 1 × 1 bottleneck convolution blocks.
                The module uses a sigmoid activation function and a residual connection between its input and output to
                reduce the difficulty of learning attentive maps.
            </p>
            <p>
            <center><img src=../img/Method-AttFetalMRI.png style="width:80%;"></center>
            </p>

            <hr>
            <center><h2>Collaborated Works</h2></center>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='../img/Result-VesselSeg-MICCAI2023.png' width=100%>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-44689-4_4">
                            Learned Local Attention Maps for Synthesising Vessel Segmentations from T2 MRI
                        </a>
                        <br>
                        Yash Deo, Rodrigo Bonazzola, <strong>Haoran Dou</strong>, Yan Xia, Tianyou Wei, Nishant
                        Ravikumar, Alejandro F Frangi, Toni Lassila
                        <br>
                        <em>MICCAI Workshop: Simulation and Synthesis in Medical Imaging</em>, 2023

                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='../img/Result-transfomer-IEEEAccess.png' width=100%>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/abstract/document/9729189">
                            Medical Image Segmentation using Transformer Networks
                        </a>
                        <br>
                        Davood Karimi, <strong>Haoran Dou</strong>, Ali Gholipour
                        <br>
                        <em>IEEE Access</em>, 2022
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='../img/Result-FetalHeadSeg-CMPB.png' width=100%>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169260719319753">
                            Hybrid Attention for Automatic Segmentation of Whole Fetal Head in Prenatal Ultrasound
                            Volumes
                        </a>
                        <br>
                        Xin Yang, Xu Wang, Yi Wang, <strong>Haoran Dou</strong>, Shengli Li, Huaxuan Wen, Yi Lin,
                        Pheng-Ann Heng, Dong Ni
                        <br>
                        <em>Computer Methods and Programs in Biomedicine</em>, 2020
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='../img/Result-BreastSeg-CMPB.png' width=100%>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169260719306583">
                            Semi-supervised Segmentation of Lesion from Breast Ultrasound Images with Attentional
                            Generative Adversarial Network
                        </a>
                        <br>
                        Luyi Han, Yunzhi Huang, <strong>Haoran Dou</strong>, Shuai Wang, Sahar Ahamad, Honghao Luo,
                        Qi Liu, Jingfan Fan, Jiang Zhang
                        <br>
                        <em>Computer Methods and Programs in Biomedicine</em>, 2020
                    </td>
                </tr>
                </tbody>
            </table>

        </td>
    </tr>


    </tbody>
</table>
</body>
</html>